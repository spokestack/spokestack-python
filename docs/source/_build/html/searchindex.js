Search.setIndex({
    docnames: [
        "index",
        "spokestack.context",
        "spokestack.mic",
        "spokestack.vad",
    ],
    envversion: {
        "sphinx.domains.c": 2,
        "sphinx.domains.changeset": 1,
        "sphinx.domains.citation": 1,
        "sphinx.domains.cpp": 3,
        "sphinx.domains.index": 1,
        "sphinx.domains.javascript": 2,
        "sphinx.domains.math": 2,
        "sphinx.domains.python": 2,
        "sphinx.domains.rst": 2,
        "sphinx.domains.std": 1,
        "sphinx.ext.viewcode": 1,
        sphinx: 56,
    },
    filenames: [
        "index.rst",
        "spokestack.context.rst",
        "spokestack.mic.rst",
        "spokestack.vad.rst",
    ],
    objects: {
        "spokestack.context": { SpeechContext: [1, 1, 1, ""] },
        "spokestack.context.SpeechContext": {
            append_buffer: [1, 2, 1, ""],
            buffer: [1, 2, 1, ""],
            clear_buffer: [1, 2, 1, ""],
            confidence: [1, 2, 1, ""],
            is_active: [1, 2, 1, ""],
            is_speech: [1, 2, 1, ""],
            reset: [1, 2, 1, ""],
            transcript: [1, 2, 1, ""],
        },
        "spokestack.mic": { pyaudio: [2, 0, 0, "-"] },
        "spokestack.mic.pyaudio": { PyAudioMicrophoneInput: [2, 1, 1, ""] },
        "spokestack.mic.pyaudio.PyAudioMicrophoneInput": {
            close: [2, 2, 1, ""],
            is_active: [2, 2, 1, ""],
            is_stopped: [2, 2, 1, ""],
            read: [2, 2, 1, ""],
            start: [2, 2, 1, ""],
            stop: [2, 2, 1, ""],
        },
        "spokestack.vad": { webrtc: [3, 0, 0, "-"] },
        "spokestack.vad.webrtc": { VoiceActivityDetector: [3, 1, 1, ""] },
        "spokestack.vad.webrtc.VoiceActivityDetector": { reset: [3, 2, 1, ""] },
        spokestack: { context: [1, 0, 0, "-"] },
    },
    objnames: {
        "0": ["py", "module", "Python module"],
        "1": ["py", "class", "Python class"],
        "2": ["py", "method", "Python method"],
    },
    objtypes: { "0": "py:module", "1": "py:class", "2": "py:method" },
    terms: {
        byte: [1, 2],
        class: [1, 2, 3],
        float: 1,
        int: [2, 3],
        return: [1, 2, 3],
        true: [1, 2],
        activ: [0, 1, 2],
        add: 1,
        append_buff: 1,
        audio: [1, 2, 3],
        base: [1, 2, 3],
        between: 1,
        bool: [1, 2],
        buffer: 1,
        classif: 1,
        clear_buff: 1,
        close: 2,
        compon: 3,
        confid: 1,
        constant: 3,
        contain: [1, 3],
        context: 0,
        current: [1, 3],
        delai: 3,
        dequ: 1,
        desir: 2,
        detect: 0,
        devic: 2,
        edg: 3,
        empti: 1,
        except: 2,
        exception_on_overflow: 2,
        fall: 3,
        fals: [1, 2],
        frame: [1, 2, 3],
        frame_width: [2, 3],
        from: 2,
        hold: 1,
        input: 0,
        is_act: [1, 2],
        is_speech: 1,
        is_stop: 2,
        kwarg: 1,
        manag: 1,
        member: 1,
        method: 1,
        mic: 2,
        microphon: 0,
        mode: 3,
        model: 1,
        modul: [1, 2, 3],
        name: 3,
        none: [1, 2, 3],
        object: [1, 2, 3],
        otherwis: [1, 2],
        overflow: 2,
        paramet: [1, 2, 3],
        pipelin: 1,
        presenc: 3,
        present: 1,
        proces: 1,
        produc: 2,
        properti: [1, 2],
        pyaudio: 2,
        pyaudiomicrophoneinput: 2,
        rate: [2, 3],
        read: 2,
        receiv: 2,
        represent: 1,
        reset: [1, 3],
        result: 1,
        retriev: 2,
        rise: 3,
        sampl: [2, 3],
        sample_r: [2, 3],
        set: [1, 3],
        singl: 2,
        sourc: [1, 2, 3],
        speech: 0,
        speechcontext: 1,
        spokestack: [1, 2, 3],
        start: 2,
        state: [1, 3],
        stop: 2,
        str: 1,
        stream: 2,
        text: 1,
        thi: [1, 2, 3],
        transcript: 1,
        type: [1, 2, 3],
        uses: 2,
        vad: 0,
        vad_fall_delai: 3,
        vad_rise_delai: 3,
        valu: 1,
        voic: 0,
        voiceactivitydetector: 3,
        webrtc: 3,
        width: [2, 3],
    },
    titles: [
        "spokestack",
        "Speech Context",
        "Microphone Input",
        "Voice Activity Detection (VAD)",
    ],
    titleterms: {
        activ: 3,
        context: 1,
        detect: 3,
        input: 2,
        microphon: 2,
        speech: 1,
        spokestack: 0,
        vad: 3,
        voic: 3,
    },
});
